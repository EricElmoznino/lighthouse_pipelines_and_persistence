{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelines and Model Persistence - W07D1\n",
    "### Instructor: Eric Elmoznino\n",
    "(Adapted from content by Arunabh Singh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview - Pipelines\n",
    "- Motivation and example\n",
    "- Feature unions\n",
    "- Visualizing pipelines\n",
    "- Hyperparameter tuning with pipelines\n",
    "- Custom class in a pipeline\n",
    "- Activity (time permitting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Motivation and example\n",
    "Consider the following example of a diabetes vs. non-diabetes classification task in Sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preg</th>\n",
       "      <th>plas</th>\n",
       "      <th>pres</th>\n",
       "      <th>skin</th>\n",
       "      <th>test</th>\n",
       "      <th>mass</th>\n",
       "      <th>pedi</th>\n",
       "      <th>age</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   preg  plas  pres  skin  test  mass   pedi  age  class\n",
       "0     6   148    72    35     0  33.6  0.627   50      1\n",
       "1     1    85    66    29     0  26.6  0.351   31      0\n",
       "2     8   183    64     0     0  23.3  0.672   32      1\n",
       "3     1    89    66    23    94  28.1  0.167   21      0\n",
       "4     0   137    40    35   168  43.1  2.288   33      1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "df = pd.read_csv(url, names=names)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 0.6948051948051948\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X = df.drop(columns='class')\n",
    "y = df['class']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=27, stratify=y)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "pca.fit(X_train_scaled)\n",
    "X_train_pca = pca.transform(X_train_scaled)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_pca, y_train)\n",
    "\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "y_pred = model.predict(X_test_pca)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f'Test set accuracy: {acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several inconvenient things about this:\n",
    "1. We have a lot of ugly code. We keep calling `.fit()` and `.transform()` on different objects, and\n",
    "we keep having to rename transformed variables so as not to cause confusions later in our notebook.\n",
    "2. Our modeling code is distributed and therefore error-prone. If we try running our model \n",
    "somewhere else and forget to copy over a step (e.g. we don't apply StandardScaler to the test set), \n",
    "then our model will not work as expected.\n",
    "3. We cannot use convenient Sklearn functions/classes such as `cross_val_score()` or `GridSearchCV()`,\n",
    "which take a single model as input. *Note that we can't just pass the final classifier/regressor to\n",
    "these functions, because our preprocessing steps (e.g. `StandardScaler`, `PCA`, etc.) must only be\n",
    "fit to the train set at each cross validation fold.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The solution: Sklearn Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 0.6948051948051948\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline(steps=[('scaling', StandardScaler()),\n",
    "                           ('pca', PCA(n_components=3)),\n",
    "                           ('classifier', LogisticRegression())])\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipeline.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f'Test set accuracy: {acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how much cleaner this code is. The composite model created using `Pipeline`\n",
    "can be used just like any other Sklearn model you have learned, which means that it\n",
    "can also be passed to functions like `cross_val_score()`.\n",
    "\n",
    "To get a better understanding of what is happening under the hood,\n",
    "let's try to build our own pipeline-like class that has some of the\n",
    "same core functionality as the Sklearn one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicPipeline:\n",
    "    \n",
    "    def __init__(self, steps):\n",
    "        self.steps = steps\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        print('Called .fit()')\n",
    "        # Fit all preprocessing modules and sequentially transform input using them\n",
    "        for name, estimator in self.steps[:-1]:\n",
    "            print(f'Fitting {name}')\n",
    "            estimator.fit(X)\n",
    "            print(f'Transforming with {name}')\n",
    "            X = estimator.transform(X)\n",
    "        \n",
    "        # Fit the final (prediction) module\n",
    "        name, estimator = self.steps[-1]\n",
    "        print(f'Fitting {name}\\n')\n",
    "        if y is not None:\n",
    "            estimator.fit(X, y)\n",
    "        else:\n",
    "            estimator.fit(X)\n",
    "        \n",
    "        # Return fitted self so that we can write things like \"model = model.fit(X, y)\",\n",
    "        # in addition to just \"model.fit(X, y)\" on its own line\n",
    "        return self\n",
    "        \n",
    "    def predict(self, X):\n",
    "        print('Called .predict()')\n",
    "        # Sequentially transform input using all the preprocessing modules\n",
    "        for name, estimator in self.steps[:-1]:\n",
    "            print(f'Transforming with {name}')\n",
    "            X = estimator.transform(X)\n",
    "        \n",
    "        # Predict using the final module\n",
    "        name, estimator = self.steps[-1]\n",
    "        print(f'Predicting with {name}\\n')\n",
    "        y_pred = estimator.predict(X)\n",
    "        \n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Called .fit()\n",
      "Fitting scaling\n",
      "Transforming with scaling\n",
      "Fitting pca\n",
      "Transforming with pca\n",
      "Fitting classifier\n",
      "\n",
      "Called .predict()\n",
      "Transforming with scaling\n",
      "Transforming with pca\n",
      "Predicting with classifier\n",
      "\n",
      "Test set accuracy: 0.6948051948051948\n"
     ]
    }
   ],
   "source": [
    "pipeline = BasicPipeline(steps=[('scaling', StandardScaler()),\n",
    "                                ('pca', PCA(n_components=3)),\n",
    "                                ('classifier', LogisticRegression())])\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipeline.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f'Test set accuracy: {acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Feature unions\n",
    "`Pipeline` lets us specify a sequence of steps that will be executed in one after the other (i.e. in `series`),\n",
    "but want if we want branches in our process? For instance, what if we want to create two different sets\n",
    "of features and use both of them when fitting our model?\n",
    "\n",
    "For this type of application, we can use a `FeatureUnion`. It is an Sklearn class that lets us join the\n",
    "outputs of several steps through *concatenation* (i.e. in parallel). `FeatureUnion`'s can be composed with `Pipeline`'s however much we want.\n",
    "\n",
    "![](images/series_and_parallel.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 0.7337662337662337\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "feature_union = FeatureUnion([('pca', PCA(n_components=3)), \n",
    "                              ('select_best', SelectKBest(k=6))])\n",
    "\n",
    "pipeline = Pipeline(steps=[('scaling', StandardScaler()),\n",
    "                           ('features', feature_union),\n",
    "                           ('classifier', LogisticRegression())])\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipeline.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f'Test set accuracy: {acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Visualizing pipelines\n",
    "Another advantage of having these pipelines is that we can quickly visualize complex workflows used in our\n",
    "modeling as HTML, which can be helpful for debugging purposes or presentations.\n",
    "\n",
    "<sub>*Note: I highly recommend you use this in your own presentations as a substitute for (or in addition to) code.*</sub>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>div.sk-top-container {color: black;background-color: white;}div.sk-toggleable {background-color: white;}label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.2em 0.3em;box-sizing: border-box;text-align: center;}div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}div.sk-estimator {font-family: monospace;background-color: #f0f8ff;margin: 0.25em 0.25em;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;}div.sk-estimator:hover {background-color: #d4ebff;}div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;}div.sk-item {z-index: 1;}div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}div.sk-parallel-item:only-child::after {width: 0;}div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0.2em;box-sizing: border-box;padding-bottom: 0.1em;background-color: white;position: relative;}div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}div.sk-label-container {position: relative;z-index: 2;text-align: center;}div.sk-container {display: inline-block;position: relative;}</style><div class=\"sk-top-container\"><div class=\"sk-container\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"3157ffb8-8637-44f7-b5e9-c804b78e2d10\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"3157ffb8-8637-44f7-b5e9-c804b78e2d10\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[('scaling', StandardScaler()),\n",
       "                ('features',\n",
       "                 FeatureUnion(transformer_list=[('pca', PCA(n_components=3)),\n",
       "                                                ('select_best',\n",
       "                                                 SelectKBest(k=6))])),\n",
       "                ('classifier', LogisticRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"369ae3a7-949a-4852-87ee-fcb42630d13c\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"369ae3a7-949a-4852-87ee-fcb42630d13c\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"c75d0fee-ccf7-405c-a50e-4a2d6369ff3b\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"c75d0fee-ccf7-405c-a50e-4a2d6369ff3b\">features: FeatureUnion</label><div class=\"sk-toggleable__content\"><pre>FeatureUnion(transformer_list=[('pca', PCA(n_components=3)),\n",
       "                               ('select_best', SelectKBest(k=6))])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>pca</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"5b47ebee-daf9-49bf-a01a-1a3d9371cde1\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"5b47ebee-daf9-49bf-a01a-1a3d9371cde1\">PCA</label><div class=\"sk-toggleable__content\"><pre>PCA(n_components=3)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>select_best</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"b858981a-5dd5-4034-954c-be9677c11fb6\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"b858981a-5dd5-4034-954c-be9677c11fb6\">SelectKBest</label><div class=\"sk-toggleable__content\"><pre>SelectKBest(k=6)</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"8abae71f-efd2-4f18-a675-58b554e9ef97\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"8abae71f-efd2-4f18-a675-58b554e9ef97\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('scaling', StandardScaler()),\n",
       "                ('features',\n",
       "                 FeatureUnion(transformer_list=[('pca', PCA(n_components=3)),\n",
       "                                                ('select_best',\n",
       "                                                 SelectKBest(k=6))])),\n",
       "                ('classifier', LogisticRegression())])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display HTML representation in a jupyter context\n",
    "from sklearn import set_config\n",
    "set_config(display='diagram')\n",
    "\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that you can also click on the individual parts in the diagram (e.g. PCA) to see their arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or, save the HTML to a file\n",
    "from sklearn.utils import estimator_html_repr\n",
    "\n",
    "with open('images/model_pipeline.html', 'w') as f:  \n",
    "    f.write(estimator_html_repr(pipeline))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Hyperparameter tuning with pipelines\n",
    "Normally, if we want to tune hyperparameters using something like `GridSearchCV`, we need to pass it:\n",
    "1. A model object.\n",
    "2. A dictionary of (parameter name, list of values to try) pairs.\n",
    "\n",
    "When not using pipelines, we can only tune hyperparameters for a single model (the one we specify as the\n",
    "model in `GridSearchCV`. As we've seen, however, we can create composite models using `Pipeline`. We can\n",
    "then pass this composite model to `GridSearchCV` and tune hyperparameters for multiple components at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best test set accuracy: 0.7467532467532467\n",
      "Achieved with hyperparameters: {'classifier__alpha': 0.001, 'features__pca__n_components': 3, 'features__select_best__k': 3}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "feature_union = FeatureUnion([('pca', PCA(n_components=3)), \n",
    "                              ('select_best', SelectKBest(k=6))])\n",
    "\n",
    "pipeline = Pipeline(steps=[('scaling', StandardScaler()),\n",
    "                           ('features', feature_union),\n",
    "                           ('classifier', RidgeClassifier())])\n",
    "\n",
    "# Find the best hyperparameters using GridSearchCV on the train set\n",
    "param_grid = {'classifier__alpha': [0.001, 0.01, 0.1], \n",
    "              'features__pca__n_components': [3, 5],\n",
    "              'features__select_best__k': [1, 3, 6]}\n",
    "grid = GridSearchCV(pipeline, param_grid=param_grid, cv=5)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "best_model = grid.best_estimator_\n",
    "best_hyperparams = grid.best_params_\n",
    "best_acc = grid.score(X_test, y_test)\n",
    "print(f'Best test set accuracy: {best_acc}\\nAchieved with hyperparameters: {best_hyperparams}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Custom class in a pipeline\n",
    "In some scenarios, the standard Sklearn models and preprocessing functions may not be enough, and you will\n",
    "have to generate your own custom classes.\n",
    "However, you'll still want the convenience of `Pipeline` and the advantages that come with it.\n",
    "\n",
    "Here, we'll see how to embed your own custom class into an Sklearn `Pipeline`. We'll be using a dummy dataset where $y = 5x_1 + 2\\sqrt{x_2}$. A linear regression model cannot find the appropriate solution, but a linear regression model that takes the square roots of the features (in addition to the features themselves) can."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.random.rand(1000, 2) * 10\n",
    "y = 5 * X[:, 0] + 2 * np.sqrt(X[:, 1])\n",
    "\n",
    "X_train, X_test, y_train, y_test = X[:600], X[600:], y[:600], y[600:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set RMSE: 0.33363728944960125\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "print(f'Test set RMSE: {rmse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance just using linear regression is poor. Let's create a custom transformer\n",
    "that generates a square-rooted version of the features, and use it in a pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# Custom Sklearn classes must:\n",
    "# a) inherit from BaseEstimator and TransformerMixin\n",
    "# b) implement the __init__(), fit(), and transform() methods\n",
    "class SqrtTransformer(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self):\n",
    "        # Your __init__ function takes in arguments as input\n",
    "        # and does some initialization, such as creating model parameters.\n",
    "        # This transformer does not require any.\n",
    "        print('init() called')\n",
    "\n",
    "    def fit(self, X, y = None):\n",
    "        # Your forward() function takes in an X (and optionally a y)\n",
    "        # and fits its parameters to the data. It then returns \"self\".\n",
    "        # This transformer does not fit anything, because it is parameterless.\n",
    "        print('fit() called')\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y = None):\n",
    "        # Your transform() function takes in an X (and optionally a y)\n",
    "        # and spits out the transformed output.\n",
    "        # This transformer returns the original features and their square root.\n",
    "        print('transform() called')\n",
    "        X_sqrt = np.sqrt(X)\n",
    "        X = np.concatenate((X, X_sqrt), axis=1)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init() called\n",
      "fit() called\n",
      "transform() called\n",
      "transform() called\n",
      "\n",
      "Test set RMSE: 1.0961584504754316e-14\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline(steps=[('sqrt', SqrtTransformer()), \n",
    "                           ('regression', LinearRegression())])\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipeline.predict(X_test)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "print(f'\\nTest set RMSE: {rmse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Activity (time permitting)\n",
    "- Go back to some sklearn code you've written in the past (either for a project or an exercise).\n",
    "- Turn it into a pipeline.\n",
    "- Post your before/after snippets in the Slack thread.\n",
    "- Meet back in 10 minutes.\n",
    "- Ask questions if you weren't sure how to do something.\n",
    "\n",
    "The goals of this exercise are to:\n",
    "- Get comfortable pipelining your preprocessing and modeling code.\n",
    "- See many paired before/after examples.\n",
    "- Fill any gap in understanding that arises when trying out pipelines yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
